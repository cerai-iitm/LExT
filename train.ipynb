{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skrit\\miniconda3\\envs\\medllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\skrit\\miniconda3\\envs\\medllm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.basic_functions import get_prediction\n",
    "from transformers import pipeline\n",
    "from src.utils import save_to_references\n",
    "from metrics.correctness import correctness\n",
    "from metrics.consistency import consistency\n",
    "from metrics.plausibility import plausibility\n",
    "from metrics.qag import qag_score\n",
    "from metrics.contextual import contextual_faithfulness\n",
    "from metrics.counterfactual import counterfactual_faithfulness\n",
    "from metrics.faithfulness import faithfulness\n",
    "from metrics.trustworthiness import lext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Models and Helper Keys Initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the ner-pipe entitiy from huggingface using which you want your explanations will be tagged. \n",
    "The below ner_pipe is a medical NER model. Other domain-specific NER models can be appropriately used for evaluating explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipe = pipeline(\"token-classification\", model=\"Clinical-AI-Apollo/Medical-NER\", aggregation_strategy='simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluation uses groq API for accessing bigger models like llama3-70b. Create an API key from Groq and replace it in the placeholder below. You can also replace the bigger model by going to [src/basic_functions.py](src/basic_functions.py) and replacing it with any othe model from groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api= \"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\"\n",
    "model =\"llama3.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the question and context, along with the ground label and explanation for computing the LeXT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I have a fever, should I take a paracetamol. Yes/No?\"\n",
    "context= None \n",
    "ground_label= \"Yes\"\n",
    "ground_explanation= \"Paracetamol is the recommended and is effective for reduction of fever in adults and children. However it is always recommended to consult with a healthcare professional before taking any medication. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Overall LExT Score\n",
    "Run the below function. All the relevant scores will be printed and the results along with the reference data for further analysis will be stored in references.csv. Make sure that the models are pulled locally on ollama and the api keys and pipelines are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fever, paracetamal\n",
      "QAG: 1.0, Counterfactual: 1.0, Contextual: 0, Faithfulness: 0.6666666666666666\n",
      "\n",
      "LExT (Language Explanation Trustworthiness) Score: 0.0\n",
      "All model outputs are saved in data/references.csv\n"
     ]
    }
   ],
   "source": [
    "LExT = lext(context, question, ground_explanation, ground_label, model, groq_api, ner_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Individual Metrics\n",
    "\n",
    "To compute any individual or aggregate set of metrics, run the below code to get the sample prediction and create a row reference dictionary that can be used to access and save data by other helper functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, explanation = get_prediction(context, question, model, groq_api, include_context=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_reference = {\n",
    "        \"ground_context\": context,\n",
    "        \"ground_question\": question,\n",
    "        \"ground_explanation\": ground_explanation,\n",
    "        \"ground_label\":ground_label,\n",
    "        \"predicted_explanation\": explanation,\n",
    "        \"predicted_label\" : label\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
